{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8HHoBd3a-SEL"
   },
   "source": [
    "# **Pipeline d'analyse des données de séquençage - Projet BILL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ReiQyvut-jdw"
   },
   "source": [
    "*Arnaud Charlery-Adèle et Daphné Navratil - M1 IMHE et Bioinformatique*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QnWkh-9scqMl"
   },
   "source": [
    "### **Contexte**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tINAOOJoG-bU"
   },
   "source": [
    "Dans le cadre du projet BILL, nous nous sommes interessés à l'effet d’un choc thermique froid sur l'évolution in vitro du Cyprinid Herpesvirus 3. Des cellules de cerveau de carpe commune ont été cultivées in vitro et inculées avec la souche italienne KHV-I du virus. Le virus a été passé en série 50 fois. Au passage 25, les cultures ont subi un choc thermique à 15°C. Pour répondre à notre problématique, le génome du virus issu des passages successifs avant et après choc thermique (P10, P20, P30, P40, P50) a été séquencé. Pour analyser les données, nous avons utilisé une pipeline décrite dans ce jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJWeNXr7_HBQ"
   },
   "source": [
    "La pipeline a été réalisée avec SnakeMake 6.14.0 avec python 3.7 par Arnaud Soulier. Elle permet de traiter les données issues du séquençage long reads Oxford Nanopore et est définie par un fichier Snakefile qui permet de lancer une suite de commandes BASH."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBBkekG2BTYY"
   },
   "source": [
    "La pipeline a été lancé individuellement pour chaque barcode et prend en entrer les fichiers fastq concaténés par barcode issus du séquençage.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZJkGN-kCotE"
   },
   "source": [
    "### **Les différentes commandes lancées par la pipeline et les logiciels auxquelles elles appartiennent sont les suivants :**\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kHZzUaXr_xca"
   },
   "source": [
    "### **Seqkit 2.1.0** [1]\n",
    "\n",
    "seqkit seq -m {trim} {input.raw} -o {output.trimed} 2> {log.out}\n",
    "\n",
    "La première étape de cette pipeline est d’utiliser Seqkit seq pour retirer des fichiers fastq les reads avec une taille inférieure à 1000 pb. La commande prend en entrer un fichier fastq.gz et donne en sortie un fichier fastq.gz.\n",
    "L'option -m permet de filtrer les reads inférieurs à une taille précisée, ici 1000, tandis que l'option -o permet de spécifier le nom du fichier de sortie.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImS78e1EDcjL"
   },
   "source": [
    "### **Minimap2 2.17** [2]\n",
    "\n",
    "minimap2 --MD -ax map-ont -t {threads} {input.ref} {input.read} -o {output.sam} 2> {log.out}\n",
    "\n",
    "Minimap2 alligne les reads issus du séquençage sur le génome de référence de la souche japonaise du virus, KHV-J. Le fichier pris en entrée est le fichier de sortie de Seqkit seq et est donc au format fastq.gz. Le fichier de sortie est un fichier sam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6CracjrtMuQm"
   },
   "source": [
    "### **Samtools 1.9**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZUMWdJlRERb"
   },
   "source": [
    "**Samtools flagstat** [3]\n",
    "\n",
    "samtools flagstat -@ {threads} {input.sorted} > {output.stats} 2> {log.out}\n",
    "\n",
    "Samtools flagstat utilise le fichier sam obtenu en sortie de l'alignement réalisé par minimap2. La commande permet d'obtenir de statistiques sur l'alignement en indiquant, en autre, le nombre de reads correspondant à chaque flag. Par exemple : le nombre de reads n'ayant pas mappés sur la référence, nombre de reads qui ont mappés partiellement etc. Le fichier de sortie est au format flagstat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o__x9bDvDcte"
   },
   "source": [
    "**samtools view** [4]\n",
    "\n",
    "samtools view -uhbS -@ {threads} -F 4 {input.sam} -o {output.mapped} 2> {log.out}\n",
    "\n",
    "Samtools convertit le fichier sam issu de minimap2 en fichier bam et de retirer les reads ne s'alignant pas sur le génome de référence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hnTfw7TALAOW"
   },
   "source": [
    "**samtools sort [5]**\n",
    "\n",
    "samtools sort -l 0 -@ {threads} {input.mapped} -o {output.sorted} 2> {log.out}\n",
    "\n",
    "A partir des fichiers bam, samtools sort sert à trier les reads selon leur position le long du chromosome pour permettre le fonctionnement de samtools index. Le fichier de sortie est au format bam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7QL_YplLhou"
   },
   "source": [
    "**samtools index [6]**\n",
    "\n",
    "samtools index -@ {threads} {input.sorted} 2> {log.out}\n",
    "\n",
    "Sniffles utilise le fichier bam indexé et prépare les reads pour l’appel de variant réalisé avec Sniffles en indexant les régions d'intérêt. Le fichier de sortie est un fichier bam.bai."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bw2w_yOqNUrz"
   },
   "source": [
    "### **sniffles 1.0.11 [7]**\n",
    "\n",
    "sniffles -t {threads} -i {input.sorted} --minsvlen 10 --minsupport 10 -v {output.vcf} 2> {log.out}\n",
    "\n",
    "Sniffles réalise l'appel de variant à partir du fichier bam de sortie de samtools sort et du fichier bam indexé. Il permet d'obtenir un fichier vcf qui liste les substitutions et indels, pour des long reads. Seules les mutations dont la longueur est supérieure ou égale à 10pb (précisé par l'option --minsvlen), et présentes sur au moins 10 reads (précisé par l'option --minsupport) ont été sélectionnées. L'option -i précise le fichier pris en entrée qui est ici le fichier bam issu de smatools sort.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FFmmLi_1Syt2"
   },
   "source": [
    "### **Deeptools 3.5.0 [8]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4pIBRQpS4MV"
   },
   "source": [
    "**bamCoverage**\n",
    "\n",
    "bamCoverage -p {threads} -b {input.sorted} -of \"bedgraph\" --effectiveGenomeSize {genomeSize} --normalizeUsing RPGC -o {output.bedgraph} 2> {log.out}\n",
    "\n",
    "Permet d'obtenir à partir du fichier bam obtenu à la sortie de samtools sort la couverture de séquençage dans un fichier appelé Bedgraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qaouBlNMToLL"
   },
   "source": [
    "**plotCoverage**\n",
    "\n",
    "plotCoverage -p {threads} -b {input.sorted} --smartLabels --plotFileFormat pdf -o {output.pdf} 2> {log.out}\n",
    "\n",
    "En prenant en entrée le fichier bam donné par la commande samtools sort, plotCoverage donne la profondeur de séquençage, c'est à dire le nombre de reads qui soutiennent un nuclétotide dans l'alignement. Le fichier de sortie est un pdf (précisé par l'option --plotFileFormat) qui contient des graphiques plotCov. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfpvNFFxh8Bi"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2UUZVomJh9Mu"
   },
   "source": [
    "### **Fichiers de sortie de la pipeline**\n",
    "\n",
    "A l'issue de la pipeline, on obtient donc:\n",
    "\n",
    "\n",
    "*   Un fichier vcf donné par Sniffles\n",
    "*   Un fichier bedgraph donné par bamCovergae\n",
    "*   Un fichier plotCov.pdf donné par plotCoverage\n",
    "*   Un fichier flagstat donné par Samtools flagstat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bY36SZjiVDj7"
   },
   "source": [
    "## **Traitement des fichiers vcf:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aw9RzFBuVcI1"
   },
   "source": [
    "Pour comparer quelles mutations sont communes ou non entre les différents passages, nous avons utilisé une commande Bcftools ainsi qu'un programme créé par Elliot Butz avec python 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0VFp8yZcWJXG"
   },
   "source": [
    "### **Bcftools 1.17 [9]**\n",
    "\n",
    "bcftools isec -n=*nombre_de_fichiers* -c all *fichiers_vcf_à_comparer*\n",
    "\n",
    "La commande bcftools isec permet de comparer les différents fichiers vcf donnés en paramètre. Avec l'option -n, on précise le nombre de fichiers que l'on souhaite comparer. Tanids que l'option -c all permet d'obtenir les variants communs entre les fichiers. Nous avons donc comparer l'ensemble des fichiers vcf obtenus pour les passage 10, 20, 30, 40 et 50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJroHEREYDPc"
   },
   "source": [
    "### **Programme python 3 par Elliot Butz**\n",
    "\n",
    "**La fonction compare_vcfs()**\n",
    "\n",
    "La classe set() permet de calculer les différences entre deux ensembles avec une complexité O(len(s)) d'après la documentation (https://python-reference.readthedocs.io/en/latest/docs/sets/op_difference.html).\n",
    "La fonction prend en entrée deux fichiers vcf à comparer et donne:\n",
    "\n",
    "*   l'ensemble des mutations présentent dans le premier fichier vcf et non dans le deuxième.\n",
    "*   l'ensemble des mutations présentent dans le second fichier vcf et non dans le premier.\n",
    "\n",
    "La fonction parcourt les fichiers et liste leurs mutations dans deux ensembles distincs. Avec des fonctionnalités de la classe set(), les mutations qui ne sont pas communes aux deux ensembles sont listés dans deux nouveaux ensembles qui sont ceux doner à la sortie de la fonction.\n",
    "\n",
    "Néanmoins cette fonctione ne fonctionne par pour l'ensemble des fichiers vcf.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b35d294jb_qC"
   },
   "outputs": [],
   "source": [
    "def compare_vcfs(vcf_file1, vcf_file2):\n",
    "    \n",
    "    # Initialisation des ensembles qui contiendront les mutations des fichiers d'entrée. \n",
    "    mutations1 = set() #mutation1 contiendra les fichiers présent dans le premier fichier vcf.\n",
    "    mutations2 = set() #mutation2 contiendra les fichiers présent dans le second fichier vcf.\n",
    "\n",
    "    \n",
    "    # Extraction des mutations du premier fichier d'entrée.\n",
    "    with open(vcf_file1, 'r') as f1: \n",
    "        \n",
    "        # Parcourt du fichier ligne par ligne.\n",
    "        for line in f1: \n",
    "            \n",
    "            # Les lignes prises en compte sont celles qui ne commencent pas par #.\n",
    "            if line[0] != '#':\n",
    "                \n",
    "                # Ajout de l'identifiant de la mutation à l'ensemble mutation1.\n",
    "                mutations1.add(tuple(line.strip().split()[:2]))\n",
    "    \n",
    "    # Extraction des mutations du second fichier d'entrée. La méthode utilisée est exactement la même\n",
    "    # que pour le premier fichier.\n",
    "    with open(vcf_file2, 'r') as f2:\n",
    "        for line in f2:\n",
    "            if line[0] != '#':\n",
    "                mutations2.add(tuple(line.strip().split()[:2]))\n",
    "\n",
    "    not_in_file2 = mutations1 - mutations2 # Retire à l'ensemble des mutations qui se trouvent dans le premier fichier\n",
    "                                           # l'ensemble des mutations qui se trouvent dans le second.\n",
    "\n",
    "    not_in_file1 = mutations2 - mutations1 # Retire à l'ensemble des mutations qui se trouvent dans le second fichier\n",
    "                                           # l'ensemble des mutations qui se trouvent dans le premier.\n",
    "\n",
    "    return (not_in_file1, not_in_file2) # Renvoie les ensembles des mutations qui différencient les deux fichiers.\n",
    "\n",
    "\n",
    "  #Nous vousinvitons à tester notre fonction. Pour cela, il suffit d'indiquer les \n",
    "#chemins d'accès à deux fichiers vcf à l'aide des deux lignes suivantes.\n",
    "\n",
    "vcf1 = '/content/P20.C1_RB03.trimed1000.mapped.sorted.vcf'\n",
    "vcf2 = '/content/P30.C1_RB04.trimed1000.mapped.sorted.vcf'\n",
    "\n",
    "print(\"Les mutations présentes dans vcf1 mais pas dans vcf2 sont : \",compare_vcfs(vcf1, vcf2)[0], \".\")\n",
    "print(\"Les mutations présentes dans vcf2 mais pas dans vcf1 sont : \",compare_vcfs(vcf1, vcf2)[1], \".\")\n",
    "  Les mutations présentes dans vcf1 mais pas dans vcf2 sont :  {('AP008984.1', '187879'), ('AP008984.1', '216398'), ('AP008984.1', '203393'), ('AP008984.1', '91777'), ('AP008984.1', '76121'), ('AP008984.1', '216445'), ('AP008984.1', '14372'), ('AP008984.1', '60348'), ('AP008984.1', '133372'), ('AP008984.1', '16050'), ('AP008984.1', '143580'), ('AP008984.1', '75785'), ('AP008984.1', '11325'), ('AP008984.1', '216397'), ('AP008984.1', '11334'), ('AP008984.1', '75786'), ('AP008984.1', '272125'), ('AP008984.1', '205799'), ('AP008984.1', '284172'), ('AP008984.1', '240065'), ('AP008984.1', '240068'), ('AP008984.1', '131128'), ('AP008984.1', '91094')} .\n",
    "Les mutations présentes dans vcf2 mais pas dans vcf1 sont :  {('AP008984.1', '22553'), ('AP008984.1', '216447'), ('AP008984.1', '49275'), ('AP008984.1', '272124'), ('AP008984.1', '29449'), ('AP008984.1', '95871'), ('AP008984.1', '165009'), ('AP008984.1', '91195'), ('AP008984.1', '91201'), ('AP008984.1', '155432'), ('AP008984.1', '31249'), ('AP008984.1', '186412'), ('AP008984.1', '90631'), ('AP008984.1', '53428'), ('AP008984.1', '22309'), ('AP008984.1', '47119'), ('AP008984.1', '270735'), ('AP008984.1', '273975')} ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFdvDCnEcOCu"
   },
   "source": [
    "**La fonction count_diffs()**\n",
    "\n",
    "Elle compte le nombre de mutations non communes aux deux fichiers vcf pris en entré. Elle donne en sortie : [texte du lien](https://)\n",
    "\n",
    "*   la taille de l'ensemble des mutations qui apparaissent dans le premier vcf pris en entrée mais pas dans le second.\n",
    "*   la taille de l'ensemble des mutations qui apparaissent dans le second vcf pris en entrée mais pas dans le premier.\n",
    "\n",
    "compare_vcf créé deux ensembles contenant les mutations qui différencient les deux vcf d'entrée et renvoie la tailles de ces deux ensembles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BU9bCaSSeZmV"
   },
   "outputs": [],
   "source": [
    "def count_diffs(vcf_file1, vcf_file2):\n",
    "    \n",
    "    # Initialisation des ensembles qui contiendront les mutations des fichiers d'entrée. \n",
    "    OnlyIn1 = compare_vcfs(vcf_file1, vcf_file2)[0] #OnlyIn1 contient les fichiers présent dans le premier fichier vcf.\n",
    "    OnlyIn2 = compare_vcfs(vcf_file1, vcf_file2)[1] #OnlyIn2 contient les fichiers présent dans le second fichier vcf.\n",
    "\n",
    "    NumberNotInFile2 = len(OnlyIn1) # Calcule la taille de l'ensemble des mutations qui se trouvent dans  \n",
    "                                    # mutations1 mais pas dans mutations2.\n",
    "\n",
    "    NumberNotInFile1 = len(OnlyIn2) # Calcule la taille de l'ensemble des mutations qui se trouvent dans  \n",
    "                                    # mutations2 mais pas dans mutations1.\n",
    "\n",
    "    return (NumberNotInFile2, NumberNotInFile1) # Renvoie des nombres de mutations qui différencient les deux fichiers.  # Voici une cellule pour tester la fonction count_diffs. Elle fait appel à l'initialisation des variables vcf1 et vcf2 deux cellules au dessus.\n",
    "\n",
    "print(\"Il y a \", count_diffs(vcf1, vcf2)[0], \" mutations présentes dans vcf1 qui n'apparaissent pas dans vcf2.\")\n",
    "print(\"Il y a \", count_diffs(vcf1, vcf2)[1], \" mutations présentes dans vcf2 qui n'apparaissent pas dans vcf1.\")  Il y a  23  mutations présentes dans vcf1 qui n'apparaissent pas dans vcf2.\n",
    "Il y a  18  mutations présentes dans vcf2 qui n'apparaissent pas dans vcf1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRC1y3QEeacB"
   },
   "source": [
    "**La fonction count_indels2()**\n",
    "\n",
    "Nous nous sommes demandé si les chocs thermiques à p25 a eut un impact sur la proportion d'insertions et de délétions détectées.\n",
    "\n",
    "La fonction prend en entré un fichier vcf et donne en sortie le nombre d'insertions et de délétions présentes dans le fichier.\n",
    "\n",
    "La fonction parcourt les lignes du fichier du fichier vcf et ignore les lignes qui comment par \"#\". La fonction parcours les différents colonnes du fichier vcf à la recherche de la chaîne \"INS\" dans la troisième colonne. Lorsque la chaîne est trouvée le compteur d'insertion augmente de 1 et dans le cas contraire c'est le compteur de déletions qui augmente de 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lUVDRpLSgQVT"
   },
   "outputs": [],
   "source": [
    "def count_indels2(vcf_file):\n",
    "    \n",
    "    # Initialisation des compteurs d'inserstions de délétions.\n",
    "    insertions = 0\n",
    "    deletions = 0\n",
    "\n",
    "    # Ouverture du fichier.\n",
    "    with open(vcf_file, 'r') as f:\n",
    "        \n",
    "        # Parcourt des lignes du fichier.\n",
    "        for line in f:\n",
    "            \n",
    "            # Si la ligne ne commence pas par le caractère #, elle n'est pas utile à la fonction.\n",
    "            if line[0] != '#':\n",
    "                \n",
    "                # Identifiaction des colonnes du fichier.\n",
    "                fields = line.strip().split('\\t')\n",
    "                \n",
    "                # Extraction du contenu de la troisième colonne.\n",
    "                id = fields[2]\n",
    "                \n",
    "                # Si la troisième colonne contient le terme \"INS\", on compte une insertion.\n",
    "                if 'INS' in id:\n",
    "                    insertions += 1\n",
    "                    \n",
    "                # Dans le cas contraire, on compte une délétion.\n",
    "                elif 'DEL' in id:\n",
    "                    deletions += 1\n",
    "                    \n",
    "                    \n",
    "    return (insertions, deletions)  # Voici une cellule pour tester la fonction count_diffs. Elle fait appel à l'initialisation des variables vcf1 et vcf2 deux cellules au dessus.\n",
    "print(\"Il y a \", count_indels2(vcf1)[0], \" insertions et \", count_indels2(vcf1)[1], \" délétions dans vcf1.\")\n",
    "print(\"Il y a \", count_indels2(vcf2)[0], \" insertions et \", count_indels2(vcf2)[1], \" délétions dans vcf2.\")\n",
    "  Il y a  14  insertions et  17  délétions dans vcf1.\n",
    "Il y a  38  insertions et  6  délétions dans vcf2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hri1AnWQgR1s"
   },
   "source": [
    "Nous avons ensuite réprésenté les résultats sous la forme d'un histogramme obtenu grâce à la fonction suivante et donné en dans le rapport en figure 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lF02P_fjgW3z"
   },
   "outputs": [],
   "source": [
    "# Importation des librairies nécessaires.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import pandas as pd\n",
    " \n",
    "# Déclaration et initialisation des données utilisées pour produire l'histogramme.\n",
    "\n",
    "r = [0,1,2,3]\n",
    "raw_data = {'orangeBars': [40, 14, 38, 20],'blueBars': [43, 17, 6, 22]} # Ces listes contiennent respectivement le nombre de délétions\n",
    "                                                                        # et d'insertions présentes à chaque passage de la culture C1.\n",
    "\n",
    "df = pd.DataFrame(raw_data)\n",
    " \n",
    "# Ici, nous transformons nos données brutes en proportions.\n",
    "\n",
    "totals = [i+j for i,j in zip(df['orangeBars'], df['blueBars'])]\n",
    "\n",
    "orangeBars = [i / j for i,j in zip(df['orangeBars'], totals)]\n",
    "blueBars = [i / j for i,j in zip(df['blueBars'], totals)]\n",
    " \n",
    "# plot\n",
    "\n",
    "barWidth = 0.85\n",
    "names = ('P10C1','P20C1','P30C1','P40C1')\n",
    "\n",
    "\n",
    "# Création des barres qui représentent les proportions d'insertions et de délétions des différents passages.\n",
    "\n",
    "plt.bar(r, orangeBars, color='#f9bc86', edgecolor='white', width=barWidth, label=\"Proportion d'insertions\")\n",
    "plt.bar(r, blueBars, bottom=orangeBars, color='#a3acff', edgecolor='white', width=barWidth, label=\"Proportion de délétions\")\n",
    "\n",
    "# Ajout des pourcentages sur les barres.\n",
    "\n",
    "for i, (r, o, b) in enumerate(zip(r, orangeBars, blueBars)):\n",
    "    plt.text(r, o / 2, '{:.0%}'.format(o), ha='center', va='center', color='white', fontsize=10)\n",
    "    plt.text(r, o + b / 2, '{:.0%}'.format(b), ha='center', va='center', color='white', fontsize=10)\n",
    "\n",
    "\n",
    "# Etiquettage des axes.\n",
    "\n",
    "plt.xticks(range(len(names)), names)\n",
    "plt.xlabel(\"Passage\")\n",
    "\n",
    "plt.ylabel(\"Proportion d'insertions et de délétions\")\n",
    "plt.ylim([0, 1])\n",
    " \n",
    "# Création de légende.\n",
    "\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1,1), ncol=1)\n",
    " \n",
    "# Affichage du graphique.\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImXCm9JKkJRK"
   },
   "source": [
    "## **Références**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cp41YzSOkOCS"
   },
   "source": [
    "[1] W Shen, S Le, Y Li*, F Hu*. SeqKit: a cross-platform and ultrafast toolkit for FASTA/Q file manipulation. PLOS ONE. doi:10.1371/journal.pone.0163962.\n",
    "\n",
    "[2] Li, H. (2018). Minimap2: pairwise alignment for nucleotide sequences. Bioinformatics, 34:3094-3100. doi:10.1093/bioinformatics/bty191\n",
    "\n",
    "[3] Li, H. Samtools. 2023. samtools flagstat – counts the number of alignments for each FLAG type; Disponible sur : http://www.htslib.org/doc/samtools-flagstat.html (Consulté le 03 mars 2023)\n",
    "\n",
    "[4] Li, H. Samtools. 2023. samtools view – views and converts SAM/BAM/CRAM files. Disponible sur : http://www.htslib.org/doc/samtools-view.html (Consulté le 03 mars 2023)\n",
    "\n",
    "[5] Li, H. Samtools. 2023. samtools sort – sorts SAM/BAM/CRAM files. Disponible sur : http://www.htslib.org/doc/samtools-sort.html (Consulté le 03 mars 2023)\n",
    "\n",
    "[6] Li, H. Samtools. 2023. samtools index – indexes SAM/BAM/CRAM files; Disponible sur : http://www.htslib.org/doc/samtools-index.html (Consulté le 03 mars 2023)\n",
    "\n",
    "[7] Sedlazeck, F.J., Rescheneder, P., Smolka, M. et al. Accurate detection of complex structural variations using single-molecule sequencing. Nat Methods 15, 461–468 (2018). https://doi.org/10.1038/s41592-018-0001-7\n",
    "\n",
    "[8] Ramírez, Fidel, Devon P. Ryan, Björn Grüning, Vivek Bhardwaj, Fabian Kilpert, Andreas S. Richter, Steffen Heyne, Friederike Dündar, and Thomas Manke. deepTools2: A next Generation Web Server for Deep-Sequencing Data Analysis. Nucleic Acids Research (2016). doi:10.1093/nar/gkw257.\n",
    "\n",
    "[9] Danecek P, Bonfield JK, Liddle J, Marshall J, Ohan V, Pollard MO, Whitwham A, Keane T, McCarthy SA, Davies RM, Li H. Twelve years of SAMtools and BCFtools. Gigascience. 2021 Feb 16;10(2):giab008. doi: 10.1093/gigascience/giab008. PMID: 33590861; PMCID: PMC7931819."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
